{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "U7fyBtvIVuci",
        "outputId": "6771169e-564d-4c15-a96f-9a67eb03313b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ac71053-af76-4e40-9d5d-00a35d2ca0b8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3ac71053-af76-4e40-9d5d-00a35d2ca0b8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving j360_tenders.xlsx to j360_tenders (1).xlsx\n",
            "Saving opportunities.xlsx to opportunities (1).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoo2JulXX4ak",
        "outputId": "084e02a4-aace-4e9b-90ba-8fe48dea7fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text classification model** to make predictions on new opportunities"
      ],
      "metadata": {
        "id": "01Qil0H4fkJl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCaJK1H3UPT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa66c2b8-e5a7-4f37-c481-a33a99983b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Other          107\n",
            "Development     15\n",
            "dtype: int64\n",
            "['Development' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Development' 'Other' 'Other' 'Development' 'Other'\n",
            " 'Other' 'Other' 'Other' 'Other' 'Other' 'Development' 'Other' 'Other'\n",
            " 'Other' 'Development' 'Development' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Other' 'Other' 'Other' 'Development' 'Development'\n",
            " 'Development' 'Development' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Development'\n",
            " 'Development' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Development' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Development' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Other' 'Other' 'Other' 'Development' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
            " 'Other' 'Other' 'Other']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "opportunities = pd.read_excel('/content/opportunities.xlsx', engine='openpyxl')\n",
        "\n",
        "# Split data into training and test sets\n",
        "X = opportunities.drop('Summary', axis=1)\n",
        "y = opportunities['Target Class']\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the 'Summary' column using TF-IDF vectorizer\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(opportunities['Summary'])\n",
        "\n",
        "# Model Selection: Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Model Training\n",
        "model.fit(X_tfidf, y)\n",
        "\n",
        "# Load new opportunities\n",
        "new_opportunities = pd.read_excel('/content/j360_tenders.xlsx', engine='openpyxl')\n",
        "\n",
        "# Cleaning the data\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    words = nltk.word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words and word.isalpha()]\n",
        "    cleaned_text = ' '.join(words)\n",
        "    return cleaned_text\n",
        "\n",
        "new_opportunities['Summary'] = new_opportunities['Summary'].apply(clean_text)\n",
        "\n",
        "# Remove duplicates\n",
        "df = new_opportunities.drop_duplicates(subset='Summary', keep='first')\n",
        "df = df.reset_index(drop=True)  # Use 'df' instead of 'new_opportunities' here\n",
        "\n",
        "# Transform the 'Summary' column using the same TF-IDF vectorizer\n",
        "X_new = tfidf_vectorizer.transform(df['Summary'])  # Use 'df' here\n",
        "\n",
        "# Make predictions for new opportunities\n",
        "new_predictions = model.predict(X_new)\n",
        "\n",
        "# Calculate the total count of each unique prediction\n",
        "prediction_counts = pd.Series(new_predictions).value_counts()\n",
        "\n",
        "# Print the counts\n",
        "print(prediction_counts)\n",
        "\n",
        "# Add 'PredictedOutcome' to the DataFrame\n",
        "df['PredictedOutcome'] = new_predictions\n",
        "\n",
        "# Writing predictions to an Excel file\n",
        "df.to_excel('predicted_opportunities.xlsx', index=False, engine='openpyxl')\n",
        "\n",
        "print(new_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear regression using scikit-learn library** to predict deadlines based on\n",
        "\n",
        "1.   Élément de liste:\n",
        "2.   Élément de liste\n",
        "\n",
        "location and the number of days until the deadline."
      ],
      "metadata": {
        "id": "j_YfOwb36Yl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "data = pd.read_excel('/content/j360_tenders.xlsx')\n",
        "\n",
        "# Convert 'Location' to numerical labels using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "data['Location'] = le.fit_transform(data['Location'])\n",
        "\n",
        "# Convert 'Deadlines' to numerical values (e.g., days from a reference date)\n",
        "reference_date = datetime(2023, 1, 1)  # Choose a reference date\n",
        "data['DaysUntilDeadline'] = (pd.to_datetime(data['Deadlines'], format='%d/%m/%Y') - reference_date).dt.days\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data['Location'].values.reshape(-1, 1)\n",
        "y = data['DaysUntilDeadline']\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model on the data\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "# predict a deadline for a specific location:\n",
        "location_code = le.transform(['Kenya'])[0]\n",
        "X_predict = [[location_code]]\n",
        "predicted_days_until_deadline = model.predict(X_predict)\n",
        "\n",
        "# Convert the predicted number of days back to a date\n",
        "predicted_deadline = reference_date + timedelta(days=int(predicted_days_until_deadline[0]))\n",
        "print(f\"Predicted Deadline: {predicted_deadline.strftime('%d/%m/%Y')}\")\n"
      ],
      "metadata": {
        "id": "BX0yyStqNpP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f999c32-f00e-4668-aa85-8fd4bf06cf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Deadline: 17/02/2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Ce texte est au format code\n",
        "```\n",
        "\n",
        "**Linear Regression Model** that provides insights into how far in advance or behind deadlines are for different countries, making it useful for prioritizing tasks or assessing project timelines."
      ],
      "metadata": {
        "id": "uCb9ZFYraXg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime\n",
        "\n",
        "data = pd.read_excel('/content/opportunities.xlsx')\n",
        "\n",
        "# Convert 'Location' to numerical labels using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "data['Country'] = le.fit_transform(data['Country'])\n",
        "country_names = le.classes_  # Get the list of country names\n",
        "\n",
        "# Convert 'Deadlines' to numerical values (e.g., days from a reference date)\n",
        "reference_date = datetime(2023, 1, 1)  # Choose a reference date\n",
        "\n",
        "# Adjust the format for parsing 'Deadline' data based on the actual formats in your data\n",
        "def parse_date(date_str):\n",
        "    try:\n",
        "        return pd.to_datetime(date_str, format='%d %b %Y')\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    return reference_date\n",
        "\n",
        "data['DaysUntilDeadline'] = (parse_date(data['Deadline']) - reference_date)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data['Country'].values.reshape(-1, 1)\n",
        "y = data['DaysUntilDeadline'].dt.days  # Access the .dt attribute to get the days\n",
        "\n",
        "# Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model on the data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now()\n",
        "\n",
        "# Calculate the predicted deadlines for each country\n",
        "data['PredictedDaysUntilDeadline'] = model.predict(X)\n",
        "\n",
        "# Calculate the difference in days between the predicted deadline and the current date\n",
        "data['DaysDifference'] = (current_date - (reference_date + pd.to_timedelta(data['PredictedDaysUntilDeadline'], unit='D'))).dt.days\n",
        "\n",
        "# Calculate the average difference in days for each country\n",
        "country_order = data.groupby('Country')['DaysDifference'].mean().reset_index()\n",
        "\n",
        "# Sort the countries based on their average difference in days (reversed order)\n",
        "country_order = country_order.sort_values(by='DaysDifference', ascending=False)\n",
        "\n",
        "# Add the country names\n",
        "country_order['CountryName'] = [country_names[i] for i in country_order['Country']]\n",
        "\n",
        "print(country_order[['CountryName', 'DaysDifference']])\n",
        "\n",
        "\n",
        "output_file = 'sorted_countries_deadlines.xlsx'\n",
        "country_order[['CountryName', 'DaysDifference']].to_excel(output_file, index=False)\n",
        "print(f\"Data saved to {output_file}\")\n"
      ],
      "metadata": {
        "id": "DX-Pkj-3ShhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89053029-3264-486a-e937-37ccaf48a2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      CountryName  DaysDifference\n",
            "0          Angola            -3.0\n",
            "1        Cameroon           -10.0\n",
            "2    Eastern Cape           -18.0\n",
            "3          France           -25.0\n",
            "4      Free State           -33.0\n",
            "5          Gambia           -40.0\n",
            "6         Gauteng           -48.0\n",
            "7           Ghana           -55.0\n",
            "8   KwaZulu-Natal           -63.0\n",
            "9         Limpopo           -70.0\n",
            "10        Morocco           -78.0\n",
            "11     Mpumalanga           -85.0\n",
            "12       National           -93.0\n",
            "13     North West          -100.0\n",
            "14  Northern Cape          -108.0\n",
            "15   South Africa          -115.0\n",
            "16         Uganda          -123.0\n",
            "17   Western Cape          -130.0\n",
            "Data saved to sorted_countries_deadlines.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The total keyword weight for every country"
      ],
      "metadata": {
        "id": "3bXk_HUzerVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/opportunities.xlsx')\n",
        "\n",
        "# Group the data by 'Country' and calculate the total keyword weight for each country\n",
        "country_grouped = data.groupby('Country')['Total_Keyword_Weight'].sum()\n",
        "\n",
        "# Iterate through the grouped data and print each country and its total keyword weight\n",
        "for country, total_weight in country_grouped.items():\n",
        "    print(f'Country: {country}, Total Keyword Weight: {total_weight}')\n"
      ],
      "metadata": {
        "id": "DLR3cTnueqx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc18c31-fa72-4220-cf3b-986272c3f8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Country: Angola, Total Keyword Weight: 8\n",
            "Country: Cameroon, Total Keyword Weight: 0\n",
            "Country: Eastern Cape, Total Keyword Weight: 66\n",
            "Country: France, Total Keyword Weight: 6\n",
            "Country: Free State, Total Keyword Weight: 5\n",
            "Country: Gambia, Total Keyword Weight: 6\n",
            "Country: Gauteng, Total Keyword Weight: 178\n",
            "Country: Ghana, Total Keyword Weight: 8\n",
            "Country: KwaZulu-Natal, Total Keyword Weight: 42\n",
            "Country: Limpopo, Total Keyword Weight: 5\n",
            "Country: Morocco, Total Keyword Weight: 14\n",
            "Country: Mpumalanga, Total Keyword Weight: 43\n",
            "Country: National, Total Keyword Weight: 49\n",
            "Country: North West, Total Keyword Weight: 12\n",
            "Country: Northern Cape, Total Keyword Weight: 6\n",
            "Country: South Africa, Total Keyword Weight: 4\n",
            "Country: Uganda, Total Keyword Weight: 8\n",
            "Country: Western Cape, Total Keyword Weight: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier** to predict opportunities based on the 'Country' and 'Total_Keyword_Weight' features. The 'OpportunityLabel' indicates whether an opportunity is considered 'better' (1) or not (0). Additionally, the feature importance of the model is provided in a separate Excel file."
      ],
      "metadata": {
        "id": "rL4laslLqgMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = pd.read_excel('/content/opportunities.xlsx')\n",
        "\n",
        "# Encode the 'Country' column\n",
        "le = LabelEncoder()\n",
        "data['Country'] = le.fit_transform(data['Country'])\n",
        "country_names = le.classes_  # Get the list of country names\n",
        "\n",
        "# the criteria for \"better\" opportunities\n",
        "data['OpportunityLabel'] = data['Total_Keyword_Weight'].apply(lambda x: 1 if x >= 10 else 0)\n",
        "\n",
        "# features and target\n",
        "X = data[['Country', 'Total_Keyword_Weight']]\n",
        "y = data['OpportunityLabel']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# the Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Add the 'OpportunityLabel' to the DataFrame\n",
        "data['OpportunityLabel'] = y\n",
        "\n",
        "# Decode the country labels back to their original names\n",
        "data['Country'] = le.inverse_transform(data['Country'])\n",
        "\n",
        "data.to_excel('/content/opportunities_with_opportunitylabel.xlsx', index=False)\n",
        "\n",
        "# New data for prediction with multiple countries\n",
        "new_data = pd.DataFrame({\n",
        "    'Country': ['France', 'France', 'Uganda'],  # Replace with actual country names\n",
        "    'Total_Keyword_Weight': [7, 37, 11]\n",
        "})\n",
        "\n",
        "# Encode the 'Country' column for the new data\n",
        "new_data['Country'] = le.transform(new_data['Country'])\n",
        "\n",
        "# Make predictions on the new data\n",
        "predictions = model.predict(new_data[['Country', 'Total_Keyword_Weight']])  # Corrected this line\n",
        "\n",
        "# Combine the predictions with the country names\n",
        "new_data['Country'] = le.inverse_transform(new_data['Country'])  # Decode back to country names\n",
        "result = pd.DataFrame({\n",
        "    'Country': new_data['Country'],\n",
        "    'Total_Keyword_Weight': new_data['Total_Keyword_Weight'],\n",
        "    'OpportunityLabel': predictions\n",
        "})\n",
        "\n",
        "print(\"Predicted Opportunities:\")\n",
        "print(result)\n",
        "\n",
        "# Display feature importance\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "feature_importance = pd.Series(importances, index=feature_names)\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)\n",
        "\n",
        "feature_importance.to_excel('/content/feature_importance.xlsx', header=['Importance'])\n"
      ],
      "metadata": {
        "id": "MwxB3yR2k71o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae166f3-c644-4449-cfdb-db7ffc368acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Predicted Opportunities:\n",
            "  Country  Total_Keyword_Weight  OpportunityLabel\n",
            "0  France                     7                 0\n",
            "1  France                    37                 1\n",
            "2  Uganda                    11                 1\n",
            "\n",
            "Feature Importance:\n",
            "Country                 0.02549\n",
            "Total_Keyword_Weight    0.97451\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forect Classifier** to predict the probability of each country being in the \"better\" category (sorting the opportunities: 1 for a good opportunity and 0 for not that good opportunities)"
      ],
      "metadata": {
        "id": "ABQf-Wffp0YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = pd.read_excel('/content/opportunities_with_opportunitylabel.xlsx')\n",
        "\n",
        "# Encode the 'Country' column\n",
        "le = LabelEncoder()\n",
        "data['Country'] = le.fit_transform(data['Country'])\n",
        "country_names = le.classes_  # Get the list of country names\n",
        "\n",
        "# Define features\n",
        "X = data[['Country', 'Total_Keyword_Weight']]\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "model.fit(X, data['OpportunityLabel'])\n",
        "\n",
        "# Predict the probability of each country being in the \"better\" category\n",
        "predicted_probabilities = model.predict_proba(X)[:, 1]\n",
        "\n",
        "# Add the predicted probabilities to the original dataset\n",
        "data['Probability_Better_Opportunity'] = predicted_probabilities\n",
        "\n",
        "# Decode the country labels back to their original names\n",
        "data['Predicted_Country'] = le.inverse_transform(data['Country'])\n",
        "\n",
        "# Group the data by country and take the maximum probability\n",
        "grouped_data = data.groupby('Predicted_Country')['Probability_Better_Opportunity'].max().reset_index()\n",
        "\n",
        "# Sort the countries by their predicted probabilities in descending order\n",
        "sorted_countries = grouped_data.sort_values(by='Probability_Better_Opportunity', ascending=False)\n",
        "\n",
        "# Display the sorted list of countries with their predicted probabilities\n",
        "print(sorted_countries)\n",
        "\n",
        "sorted_countries.to_excel('/content/sorted_countries_with_probabilities.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "lWV0VO77l1hf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48474c5b-20e1-4baf-8a85-0485577a6258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Predicted_Country  Probability_Better_Opportunity\n",
            "6            Gauteng                            1.00\n",
            "2       Eastern Cape                            0.92\n",
            "11        Mpumalanga                            0.84\n",
            "8      KwaZulu-Natal                            0.84\n",
            "0             Angola                            0.00\n",
            "16            Uganda                            0.00\n",
            "15      South Africa                            0.00\n",
            "14     Northern Cape                            0.00\n",
            "13        North West                            0.00\n",
            "12          National                            0.00\n",
            "9            Limpopo                            0.00\n",
            "10           Morocco                            0.00\n",
            "1           Cameroon                            0.00\n",
            "7              Ghana                            0.00\n",
            "5             Gambia                            0.00\n",
            "4         Free State                            0.00\n",
            "3             France                            0.00\n",
            "17      Western Cape                            0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression models to predict the frequency of opportunities (I can not do this because I do not have the posting date.)"
      ],
      "metadata": {
        "id": "ebEc6Zvg_cTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indicators"
      ],
      "metadata": {
        "id": "tPUKi9ArilII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Number of future tenders per country per sector\n",
        "*   How many tenders we will have based on our target class\n",
        "*  Which countries are in each target class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0PLa-XmzkGjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/opportunities.xlsx')\n",
        "\n",
        "# Group the data by 'Country' and 'Sector' and count the number of tenders in each group\n",
        "tenders_per_country_per_sector = df.groupby(['Country', 'Sector']).size().reset_index(name='TenderCount')\n",
        "\n",
        "# Count the occurrences of each class\n",
        "tender_counts_by_target_class = df['Target Class'].value_counts().reset_index()\n",
        "tender_counts_by_target_class.columns = ['Target Class', 'Count']\n",
        "\n",
        "\n",
        "# Group the data by 'TargetClass' and aggregate the unique countries associated with each class\n",
        "countries_by_target_class = df.groupby('Target Class')['Country'].unique().reset_index()\n",
        "\n",
        "# Create a new DataFrame with 'Country' and 'Target Class' columns\n",
        "result_df = countries_by_target_class.explode('Country')\n",
        "\n",
        "\n",
        "result_df.columns = ['Target Class', 'Country']\n",
        "\n",
        "\n",
        "with pd.ExcelWriter('/content/output_indicators.xlsx') as writer:\n",
        "    tenders_per_country_per_sector.to_excel(writer, sheet_name='Tenders by Country & Sector', index=False)\n",
        "    tender_counts_by_target_class.to_excel(writer, sheet_name='Target Class Counts', index=False)\n",
        "    countries_by_target_class.apply(pd.Series).to_excel(writer, sheet_name='Countries by Target Class', index=False)\n"
      ],
      "metadata": {
        "id": "CWhRieh2pBNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of opportunities by year, by month and by day"
      ],
      "metadata": {
        "id": "08acCn0mpCYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/opportunities.xlsx')\n",
        "\n",
        "# \"Deadline\" column is in datetime format\n",
        "data['Deadline'] = pd.to_datetime(data['Deadline'])\n",
        "\n",
        "# Extract the year, month, and day from the \"Deadline\" column\n",
        "data['Year'] = data['Deadline'].dt.year\n",
        "data['Month'] = data['Deadline'].dt.month\n",
        "data['Day'] = data['Deadline'].dt.day\n",
        "\n",
        "# the total count of opportunities for every year\n",
        "opportunities_by_year = data.groupby(['Year']).size().reset_index(name='Opportunity Count (Year)')\n",
        "\n",
        "# the total count of opportunities for every month\n",
        "opportunities_by_month = data.groupby(['Year', 'Month']).size().reset_index(name='Opportunity Count (Month)')\n",
        "\n",
        "# the total count of opportunities for every day\n",
        "opportunities_by_day = data.groupby(['Year', 'Month', 'Day']).size().reset_index(name='Opportunity Count (Day)')\n",
        "\n",
        "# the overall total count of opportunities\n",
        "total_opportunities = len(data)\n",
        "\n",
        "\n",
        "print(\"Opportunities by Year:\")\n",
        "print(opportunities_by_year)\n",
        "print(\"\\nOpportunities by Month:\")\n",
        "print(opportunities_by_month)\n",
        "print(\"\\nOpportunities by Day:\")\n",
        "print(opportunities_by_day)\n",
        "\n",
        "\n",
        "with pd.ExcelWriter('opportunity_counts.xlsx') as writer:\n",
        "    opportunities_by_year.to_excel(writer, sheet_name='Opportunities by Year', index=False)\n",
        "    opportunities_by_month.to_excel(writer, sheet_name='Opportunities by Month', index=False)\n",
        "    opportunities_by_day.to_excel(writer, sheet_name='Opportunities by Day', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pOSbcozvk5m3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b65864c-a7d0-4bda-fa28-63a59fa4b070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opportunities by Year:\n",
            "   Year  Opportunity Count (Year)\n",
            "0  2023                       188\n",
            "1  2024                        12\n",
            "2  2025                         5\n",
            "3  2026                         3\n",
            "4  2027                         2\n",
            "5  2030                         2\n",
            "\n",
            "Opportunities by Month:\n",
            "    Year  Month  Opportunity Count (Month)\n",
            "0   2023      3                          1\n",
            "1   2023      9                        123\n",
            "2   2023     10                         53\n",
            "3   2023     11                          2\n",
            "4   2023     12                          9\n",
            "5   2024      2                          1\n",
            "6   2024      3                          1\n",
            "7   2024      6                          2\n",
            "8   2024      8                          1\n",
            "9   2024      9                          1\n",
            "10  2024     12                          6\n",
            "11  2025      3                          1\n",
            "12  2025     10                          3\n",
            "13  2025     12                          1\n",
            "14  2026      6                          1\n",
            "15  2026     12                          2\n",
            "16  2027      9                          1\n",
            "17  2027     12                          1\n",
            "18  2030     12                          2\n",
            "\n",
            "Opportunities by Day:\n",
            "    Year  Month  Day  Opportunity Count (Day)\n",
            "0   2023      3   31                        1\n",
            "1   2023      9   14                       13\n",
            "2   2023      9   15                       25\n",
            "3   2023      9   18                        5\n",
            "4   2023      9   19                       17\n",
            "5   2023      9   20                        6\n",
            "6   2023      9   21                        6\n",
            "7   2023      9   22                       16\n",
            "8   2023      9   25                        5\n",
            "9   2023      9   26                        9\n",
            "10  2023      9   27                        6\n",
            "11  2023      9   28                        4\n",
            "12  2023      9   29                       10\n",
            "13  2023      9   30                        1\n",
            "14  2023     10    2                        3\n",
            "15  2023     10    3                        4\n",
            "16  2023     10    4                        5\n",
            "17  2023     10    5                        3\n",
            "18  2023     10    6                        5\n",
            "19  2023     10    9                        3\n",
            "20  2023     10   10                        1\n",
            "21  2023     10   11                        4\n",
            "22  2023     10   12                        2\n",
            "23  2023     10   13                        5\n",
            "24  2023     10   16                        1\n",
            "25  2023     10   17                        2\n",
            "26  2023     10   25                        1\n",
            "27  2023     10   26                        2\n",
            "28  2023     10   27                        2\n",
            "29  2023     10   30                        2\n",
            "30  2023     10   31                        8\n",
            "31  2023     11    9                        1\n",
            "32  2023     11   10                        1\n",
            "33  2023     12   12                        4\n",
            "34  2023     12   16                        1\n",
            "35  2023     12   31                        4\n",
            "36  2024      2    1                        1\n",
            "37  2024      3   13                        1\n",
            "38  2024      6   30                        2\n",
            "39  2024      8   19                        1\n",
            "40  2024      9   16                        1\n",
            "41  2024     12   12                        3\n",
            "42  2024     12   31                        3\n",
            "43  2025      3   31                        1\n",
            "44  2025     10   31                        3\n",
            "45  2025     12   12                        1\n",
            "46  2026      6   30                        1\n",
            "47  2026     12   16                        1\n",
            "48  2026     12   31                        1\n",
            "49  2027      9    1                        1\n",
            "50  2027     12   31                        1\n",
            "51  2030     12   31                        2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of opportunities by year for every country"
      ],
      "metadata": {
        "id": "jn2Ed3LlpLXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/opportunities.xlsx')\n",
        "\n",
        "# \"Deadline\" column is in datetime format\n",
        "data['Deadline'] = pd.to_datetime(data['Deadline'])\n",
        "\n",
        "# Filter the dataset to include only future tenders (those with a Deadline greater than or equal to today)\n",
        "today = pd.to_datetime('today')\n",
        "future_tenders = data[data['Deadline'] >= today]\n",
        "\n",
        "# Extract the year\n",
        "future_tenders['Year'] = future_tenders['Deadline'].dt.year\n",
        "\n",
        "# Group the data by country, year, and count the number of future tenders for each group\n",
        "future_tenders_by_country_year = future_tenders.groupby(['Country', 'Year']).size().reset_index(name='Tender Count')\n",
        "\n",
        "print(future_tenders_by_country_year)\n",
        "\n",
        "future_tenders_by_country_year.to_excel('future_tenders_by_country_year.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "sflhmjOfnduo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8175f09-c069-46aa-9ebd-bfa74abfa013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Country  Year  Tender Count\n",
            "0         Angola  2023             2\n",
            "1         Angola  2024             1\n",
            "2         France  2023             6\n",
            "3         France  2024             1\n",
            "4         France  2026             1\n",
            "5         Gambia  2023             1\n",
            "6         Gambia  2025             1\n",
            "7        Gauteng  2023             2\n",
            "8          Ghana  2023             1\n",
            "9          Ghana  2024             6\n",
            "10         Ghana  2026             1\n",
            "11       Morocco  2023             2\n",
            "12       Morocco  2024             1\n",
            "13       Morocco  2025             1\n",
            "14       Morocco  2027             1\n",
            "15       Morocco  2030             2\n",
            "16  South Africa  2023             1\n",
            "17  South Africa  2024             3\n",
            "18  South Africa  2025             3\n",
            "19        Uganda  2023             4\n",
            "20        Uganda  2026             1\n",
            "21        Uganda  2027             1\n",
            "22  Western Cape  2023             2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-3d10b23489e7>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  future_tenders['Year'] = future_tenders['Deadline'].dt.year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the opportunities based on country and month"
      ],
      "metadata": {
        "id": "TsyBRFNCrn_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/opportunities.xlsx')\n",
        "\n",
        "# \"Deadline\" column is in datetime format\n",
        "df['Deadline'] = pd.to_datetime(df['Deadline'])\n",
        "\n",
        "# Extract the month from the \"Deadline\" column\n",
        "df['Month'] = df['Deadline'].dt.month\n",
        "\n",
        "# Display the DataFrame with the \"Country\" and \"Month\" columns\n",
        "result_df = df[['Country', 'Month']]\n",
        "print(result_df)\n",
        "\n",
        "\n",
        "with pd.ExcelWriter('/content/country_month_data.xlsx') as writer:\n",
        "    df[['Country', 'Month']].to_excel(writer, sheet_name='Country vs Month', index=False)\n"
      ],
      "metadata": {
        "id": "B4Ap3pR0rqO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5aa7395-5b34-41d9-98e7-7e30cca26f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Country  Month\n",
            "0          Gauteng      9\n",
            "1       Mpumalanga      9\n",
            "2          Gauteng      9\n",
            "3     Eastern Cape     10\n",
            "4          Gauteng      9\n",
            "..             ...    ...\n",
            "207  KwaZulu-Natal      9\n",
            "208        Gauteng     10\n",
            "209     Mpumalanga      9\n",
            "210        Gauteng      9\n",
            "211   Eastern Cape      9\n",
            "\n",
            "[212 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT6wBCE3NIcI",
        "outputId": "8398e26d-b238-46fa-ff22-dc1e0b32a749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.10/dist-packages (3.1.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "excel_files = ['country_month_data.xlsx', 'feature_importance.xlsx', 'future_tenders_by_country_year.xlsx', 'opportunity_counts.xlsx', 'output_indicators.xlsx', 'predicted_opportunities.xlsx', 'sorted_countries_deadlines.xlsx', 'sorted_countries_with_probabilities.xlsx']\n",
        "\n",
        "excel_writer = pd.ExcelWriter('predictions.xlsx', engine='xlsxwriter')\n",
        "\n",
        "# giving a name to every sheet\n",
        "for excel_file in excel_files:\n",
        "    sheet_name = os.path.splitext(os.path.basename(excel_file))[0][:31]\n",
        "    df = pd.read_excel(excel_file)\n",
        "    df.to_excel(excel_writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "excel_writer.save()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ix9xEomLhF_",
        "outputId": "71a49afe-6694-4f98-b6b8-9104d989a38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-3dbac25c7309>:13: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  excel_writer.save()\n"
          ]
        }
      ]
    }
  ]
}